{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta, datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def Getting_Flight_Info(URL):\n",
    "    driver = webdriver.Chrome('/Users/robjohns/Documents/Metis/Project2/chromedriver')\n",
    "    driver.get(URL)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.quit()\n",
    "    data=DataGetter(URL,soup)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-07-22', '2019-09-03', '2019-10-16', '2019-11-28', '2019-07-22', '2019-09-03', '2019-10-16', '2019-11-28']\n",
      "['https://www.google.com/flights?hl=en#flt=SEA.SFO.2019-07-22;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.SFO.2019-09-03;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.SFO.2019-10-16;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.SFO.2019-11-28;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.ORD.2019-07-22;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.ORD.2019-09-03;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.ORD.2019-10-16;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o', 'https://www.google.com/flights?hl=en#flt=SEA.ORD.2019-11-28;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o']\n"
     ]
    }
   ],
   "source": [
    "print(super_short_test_list_dates)\n",
    "print(super_short_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of flights: 30\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 27\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 27\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 21\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 20\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 18\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 18\n",
      "\n",
      "did 2019-11-28\n",
      "num of flights: 12\n",
      "\n",
      "did 2019-11-28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for URL in super_short_test_list:\n",
    "    data=Getting_Flight_Info(URL)\n",
    "    data=pd.DataFrame(data)\n",
    "    \n",
    "    Locations = re.search('#flt=(.+?);b:1', URL).group(1)\n",
    "    Spots=Locations.split('.')\n",
    "    Departure=Spots[0]\n",
    "    Arrival = Spots[1]\n",
    "    Date= Spots[2]\n",
    "    Date=Date.replace('-',\"_\")\n",
    "     \n",
    "    data.to_pickle(f'Picklefolder/{Departure}_{Arrival}_{Date}')\n",
    "    print(f'did {name}')\n",
    "\n",
    "#testy=pd.read_pickle('Picklefolder/testpickle')\n",
    "#print(testy)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir('Picklefolder/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEA_SFO_2019_09_03',\n",
       " 'SEA_ORD_2019_10_16',\n",
       " '.DS_Store',\n",
       " 'SEA_ORD_2019_11_28',\n",
       " 'SEA_ORD_2019_07_22',\n",
       " 'SEA_SFO_2019_07_22',\n",
       " 'SEA_SFO_2019_10_16',\n",
       " 'SEA_ORD_2019_09_03',\n",
       " 'SEA_SFO_2019_11_28']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0           1    2    3   \\\n",
      "0    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "1    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "2    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "3    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "4    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "5    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "6    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "7    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "8    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "9    https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "10   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "11   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "12   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "13   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "14   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "15   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "16   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "17   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "18   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "19   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "20   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "21   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "22   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "23   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "24   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "25   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "26   https://www.google.com/flights?hl=en#flt=SEA.S...  2019-09-03  SEA  SFO   \n",
      "27   https://www.google.com/flights?hl=en#flt=SEA.O...  2019-10-16  SEA  ORD   \n",
      "28   https://www.google.com/flights?hl=en#flt=SEA.O...  2019-10-16  SEA  ORD   \n",
      "29   https://www.google.com/flights?hl=en#flt=SEA.O...  2019-10-16  SEA  ORD   \n",
      "..                                                 ...         ...  ...  ...   \n",
      "143  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "144  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "145  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "146  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "147  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "148  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "149  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "150  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "151  https://www.google.com/flights?hl=en#flt=SEA.O...  2019-09-03  SEA  ORD   \n",
      "152  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "153  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "154  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "155  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "156  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "157  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "158  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "159  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "160  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "161  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "162  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "163  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "164  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "165  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "166  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "167  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "168  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "169  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "170  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "171  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "172  https://www.google.com/flights?hl=en#flt=SEA.S...  2019-11-28  SEA  SFO   \n",
      "\n",
      "       4      5        6        7         8   \\\n",
      "0    2.15  119.0   9:35 P  11:44 P    Alaska   \n",
      "1    2.20  122.0   9:22 A  11:34 A     Delta   \n",
      "2    2.15  124.0   6:00 A   8:09 A    United   \n",
      "3    2.25  119.0   7:45 A  10:00 A    Alaska   \n",
      "4    2.25  119.0   9:50 A  12:05 P    Alaska   \n",
      "5    2.17  119.0   8:30 P  10:40 P    Alaska   \n",
      "6    2.22  122.0  11:15 A   1:28 P     Delta   \n",
      "7    2.22  124.0   7:00 A   9:13 A    United   \n",
      "8    2.37  124.0   9:51 A  12:13 P    United   \n",
      "9    2.22  124.0   1:00 P   3:13 P    United   \n",
      "10   2.17  139.0   2:50 P   5:00 P    Alaska   \n",
      "11   2.17  139.0   7:20 P   9:30 P    Alaska   \n",
      "12   2.17  156.0   7:41 P   9:51 P    United   \n",
      "13   2.25  159.0   6:30 A   8:45 A    Alaska   \n",
      "14   2.42  159.0   6:45 A   9:10 A    Alaska   \n",
      "15   2.25  159.0  12:40 P   2:55 P    Alaska   \n",
      "16   2.25  159.0   1:35 P   3:50 P    Alaska   \n",
      "17   2.17  159.0   3:40 P   5:50 P    Alaska   \n",
      "18   2.12  169.0   7:20 A   9:27 A     Delta   \n",
      "19   2.08  169.0   3:25 P   5:30 P     Delta   \n",
      "20   2.28  169.0   6:05 P   8:22 P     Delta   \n",
      "21   2.25  179.0  11:40 A   1:55 P    Alaska   \n",
      "22   2.17  179.0   5:30 P   7:40 P    Alaska   \n",
      "23   2.20  196.0   4:18 P   6:30 P    United   \n",
      "24   2.20  196.0   5:15 P   7:27 P    United   \n",
      "25   2.25  243.0   1:15 P   3:30 P     Delta   \n",
      "26   2.17  327.0   9:20 P  11:30 P     Delta   \n",
      "27   4.02   82.0   7:00 A   1:01 P     Delta   \n",
      "28   4.08   82.0   5:35 P  11:40 P    Alaska   \n",
      "29   3.85   82.0   5:55 P  11:46 P     Delta   \n",
      "..    ...    ...      ...      ...       ...   \n",
      "143  4.00  246.0   7:06 A   1:06 P     Delta   \n",
      "144  3.87  251.0  11:28 P   5:20 A    United   \n",
      "145  4.32  282.0  10:01 A   4:20 P  American   \n",
      "146  4.30  282.0   1:21 P   7:39 P  American   \n",
      "147  4.25  297.0   8:20 A   2:35 P    Alaska   \n",
      "148  3.93  299.0   7:05 A   1:01 P    United   \n",
      "149  4.15  299.0   1:41 P   7:50 P    United   \n",
      "150  4.15  346.0  10:30 A   4:39 P    United   \n",
      "151  4.25  363.0  12:05 P   6:20 P    Alaska   \n",
      "152  2.08   87.0   8:00 A  10:05 A    Alaska   \n",
      "153  2.08   87.0  10:30 P  12:35 A    Alaska   \n",
      "154  2.30   92.0   7:30 A   9:48 A     Delta   \n",
      "155  2.33   92.0   9:05 A  11:25 A     Delta   \n",
      "156  2.18  107.0  12:15 P   2:26 P    United   \n",
      "157  2.30  107.0   6:00 A   8:18 A    United   \n",
      "158  2.33  107.0   7:30 A   9:50 A    United   \n",
      "159  2.22  107.0   1:21 P   3:34 P    United   \n",
      "160  2.08  119.0  11:00 A   1:05 P    Alaska   \n",
      "161  2.08  119.0  12:00 P   2:05 P    Alaska   \n",
      "162  2.08  119.0   2:00 P   4:05 P    Alaska   \n",
      "163  2.08  119.0   3:30 P   5:35 P    Alaska   \n",
      "164  2.08  119.0   8:30 P  10:35 P    Alaska   \n",
      "165  2.08  119.0   9:30 P  11:35 P    Alaska   \n",
      "166  2.32  137.0   9:35 A  11:54 A    United   \n",
      "167  2.08  139.0   6:00 A   8:05 A    Alaska   \n",
      "168  2.08  139.0   9:45 A  11:50 A    Alaska   \n",
      "169  2.08  139.0   7:30 P   9:35 P    Alaska   \n",
      "170  2.08  159.0   7:00 A   9:05 A    Alaska   \n",
      "171  2.08  159.0   5:30 P   7:35 P    Alaska   \n",
      "172  2.27  327.0  11:11 A   1:27 P     Delta   \n",
      "\n",
      "                                       9   \\\n",
      "0                                  AS1330   \n",
      "1                  (REGEXerror:, DL 2429)   \n",
      "2                                   UA368   \n",
      "3                                   AS405   \n",
      "4                                  AS1746   \n",
      "5                                  AS1328   \n",
      "6                  (REGEXerror:, DL 1470)   \n",
      "7                                  UA1216   \n",
      "8                                   UA698   \n",
      "9                                   UA816   \n",
      "10                                  AS368   \n",
      "11                                 AS1748   \n",
      "12                                 UA2070   \n",
      "13                                  AS762   \n",
      "14   (REGEXerror:, Embraer RJ-175AS 2950)   \n",
      "15                                 AS1758   \n",
      "16                                  AS306   \n",
      "17                                 AS1754   \n",
      "18                 (REGEXerror:, DL 2490)   \n",
      "19                 (REGEXerror:, DL 2191)   \n",
      "20                 (REGEXerror:, DL 1455)   \n",
      "21                                 AS1750   \n",
      "22                                 AS1756   \n",
      "23                                 UA1494   \n",
      "24                                  UA587   \n",
      "25                 (REGEXerror:, DL 2002)   \n",
      "26                 (REGEXerror:, DL 2621)   \n",
      "27                                 DL1247   \n",
      "28                                 AS1026   \n",
      "29                                  DL853   \n",
      "..                                    ...   \n",
      "143                                DL2036   \n",
      "144                                 UA619   \n",
      "145                                 AA228   \n",
      "146                                AA1045   \n",
      "147                                  AS34   \n",
      "148                                UA2287   \n",
      "149                                 UA670   \n",
      "150                                 UA278   \n",
      "151                                  AS22   \n",
      "152                                 AS405   \n",
      "153                                 AS406   \n",
      "154                (REGEXerror:, DL 2490)   \n",
      "155                (REGEXerror:, DL 2429)   \n",
      "156                                 UA526   \n",
      "157                                UA2332   \n",
      "158                                UA1216   \n",
      "159                                 UA816   \n",
      "160                                 AS304   \n",
      "161                                AS1750   \n",
      "162                                AS1752   \n",
      "163                                AS1754   \n",
      "164                                AS1748   \n",
      "165                                AS1328   \n",
      "166                                 UA698   \n",
      "167                                 AS762   \n",
      "168                                AS1746   \n",
      "169                                 AS376   \n",
      "170  (REGEXerror:, Embraer RJ-175AS 2251)   \n",
      "171                                AS1756   \n",
      "172                (REGEXerror:, DL 1470)   \n",
      "\n",
      "                                       10  \n",
      "0                             Airbus A320  \n",
      "1                  (REGEXerror:, DL 2429)  \n",
      "2                             Airbus A320  \n",
      "3                              Boeing 737  \n",
      "4                             Airbus A320  \n",
      "5                             Airbus A320  \n",
      "6                  (REGEXerror:, DL 1470)  \n",
      "7                              Boeing 737  \n",
      "8                              Boeing 737  \n",
      "9                              Boeing 737  \n",
      "10                             Boeing 737  \n",
      "11                            Airbus A320  \n",
      "12                             Boeing 737  \n",
      "13                             Boeing 737  \n",
      "14   (REGEXerror:, Embraer RJ-175AS 2950)  \n",
      "15                            Airbus A320  \n",
      "16                             Boeing 737  \n",
      "17                            Airbus A320  \n",
      "18                 (REGEXerror:, DL 2490)  \n",
      "19                 (REGEXerror:, DL 2191)  \n",
      "20                 (REGEXerror:, DL 1455)  \n",
      "21                            Airbus A320  \n",
      "22                            Airbus A320  \n",
      "23                             Boeing 737  \n",
      "24                             Boeing 737  \n",
      "25                 (REGEXerror:, DL 2002)  \n",
      "26                 (REGEXerror:, DL 2621)  \n",
      "27                             Boeing 737  \n",
      "28                            Airbus A320  \n",
      "29                            Airbus A319  \n",
      "..                                    ...  \n",
      "143                            Boeing 737  \n",
      "144                            Boeing 737  \n",
      "145                            Boeing 737  \n",
      "146                            Boeing 737  \n",
      "147                            Boeing 737  \n",
      "148                            Boeing 737  \n",
      "149                            Boeing 737  \n",
      "150                            Boeing 757  \n",
      "151                            Boeing 737  \n",
      "152                            Boeing 737  \n",
      "153                            Boeing 737  \n",
      "154                (REGEXerror:, DL 2490)  \n",
      "155                (REGEXerror:, DL 2429)  \n",
      "156                            Boeing 737  \n",
      "157                           Airbus A320  \n",
      "158                           Airbus A319  \n",
      "159                           Airbus A320  \n",
      "160                            Boeing 737  \n",
      "161                           Airbus A320  \n",
      "162                           Airbus A320  \n",
      "163                           Airbus A320  \n",
      "164                           Airbus A320  \n",
      "165                           Airbus A320  \n",
      "166                           Airbus A319  \n",
      "167                            Boeing 737  \n",
      "168                           Airbus A320  \n",
      "169                            Boeing 737  \n",
      "170  (REGEXerror:, Embraer RJ-175AS 2251)  \n",
      "171                           Airbus A320  \n",
      "172                (REGEXerror:, DL 1470)  \n",
      "\n",
      "[173 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#testy=pd.read_pickle('Picklefolder/testpickle')\n",
    "\n",
    "#list the files\n",
    "filelist = os.listdir('Picklefolder/') \n",
    "#read them into pandas\n",
    "df_list = [pd.read_pickle(f'Picklefolder/{file}') for file in filelist if file[0]!='.']\n",
    "#concatenate them together\n",
    "df = pd.concat(df_list,ignore_index=True)\n",
    "print(df)\n",
    "#print(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to avoid booting from server ideas . . . .\n",
    "for page in super_short_test_list:\n",
    "    ### scrape a website\n",
    "    ### ...\n",
    "    print(page)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #time.sleep(.5+2*random.random())\n",
    "    \n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.reddit.com'\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = {'User-agent': ua.random}\n",
    "print(user_agent)\n",
    "\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##this will take the soupy html file and pull out data values for all flight results from a search##\n",
    "# looking for [Date,DepartureCity,ArrivalCity,DepartureTime,\n",
    "#               ArrivalTime,FlightDuration,Price,PlaneType,Airline,FlightNumber]\n",
    "import re\n",
    "#'https://www.google.com/flights?hl=en#flt=SFO.AUS.2019-08-21;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "#each page has a different number of flights on it, so for this URL we need to make a list of lists\n",
    "#that is the length = number of flights on the page#\n",
    "\n",
    "\n",
    "def DataGetter(URL,soup):\n",
    "\n",
    "    Locations = re.search('#flt=(.+?);b:1', URL).group(1)\n",
    "    Spots=Locations.split('.')\n",
    "    Departure=Spots[0]\n",
    "    Arrival = Spots[1]\n",
    "    Date= Spots[2]\n",
    "\n",
    "\n",
    "\n",
    "    flights=len(soup.find_all('div', attrs={'class': 'gws-flights-results__itinerary-duration'}))\n",
    "    print('num of flights:',flights)\n",
    "    BigList = [[] for _ in range(flights)]\n",
    "    for flight in BigList:\n",
    "        flight.append(URL)\n",
    "        flight.append(Date)\n",
    "        flight.append(Departure)\n",
    "        flight.append(Arrival)\n",
    "\n",
    "    # Append flight durations onto each element of the list\n",
    "    i=-1\n",
    "    for li in soup.find_all('div', attrs={'class': 'gws-flights-results__duration flt-subhead1Normal'}):\n",
    "        i+=1\n",
    "        chonk=li.get_text()\n",
    "        try:\n",
    "            ch=chonk.split('h')\n",
    "            onk=chonk.split(' ')\n",
    "            num2=onk[1]\n",
    "            flight_duration=float(ch[0])+(float(num2[:-1])/60)\n",
    "            flight_duration = round(flight_duration,2)\n",
    "            BigList[i].append(flight_duration)\n",
    "            #print ('flight_duration:',flight_duration)\n",
    "        except:\n",
    "            BigList[i].append('NaN')\n",
    "            print('There was an issue')\n",
    "\n",
    "\n",
    "\n",
    "    #for li in soup.find_all('div', attrs={'class': 'gws-flights-results__price'}):\n",
    "        #print(li)\n",
    "\n",
    "\n",
    "    #here we add more flight info from the jstcache. . . beware this number seems to change from day to day\n",
    "    i=-1\n",
    "    for li in soup.find_all('jsl', attrs={'jstcache': \"8836\"}):\n",
    "        i+=1\n",
    "        text = li.get_text()\n",
    "\n",
    "          #finding price\n",
    "        try:\n",
    "            found = re.search('From (.+?)Trip', text).group(1)\n",
    "            dollar=found.replace(',','')\n",
    "            found=float(dollar[1:-1])\n",
    "        except AttributeError:\n",
    "        # if the sentence structure i didnt expect show up\n",
    "            found = 'NaN' # apply your error handling\n",
    "        #print('cost:',found)\n",
    "        BigList[i].append(found)\n",
    "        #finding departure and arrival times\n",
    "        try:\n",
    "            found = re.search('Departure time: (.+?)M', text).group(1)\n",
    "            found2 = re.search('Arrival time: (.+?)M', text).group(1)\n",
    "\n",
    "            #departure=found.replace(',','')\n",
    "            #found=float(dollar[1:-1])\n",
    "        except AttributeError:\n",
    "        # if the sentence structure i didnt expect show up\n",
    "            found = 'NaN' # apply your error handling\n",
    "        #print('Departure Time:',found)\n",
    "        #print('Arrival Time:',found2)\n",
    "        BigList[i].append(found)\n",
    "        BigList[i].append(found2)\n",
    "\n",
    "\n",
    "        #grab airline\n",
    "        try:\n",
    "            found = re.search('by (.+?).Depa', text).group(1)\n",
    "\n",
    "            #departure=found.replace(',','')\n",
    "            #found=float(dollar[1:-1])\n",
    "        except AttributeError:\n",
    "        # if the sentence structure i didnt expect show up\n",
    "            found = 'NaN' # apply your error handling\n",
    "        #print('Airline:',found)\n",
    "        BigList[i].append(found)\n",
    "    #print('')\n",
    "        #grab PlaneType and flight number\n",
    "    i=-1    \n",
    "    for li in soup.find_all('div', attrs={'class': 'gws-flights-results__other-leg-info'}):\n",
    "            i+=1\n",
    "            #print(li.get_text())\n",
    "            st=li.get_text()\n",
    "            #st=str(st.text())\n",
    "            result = re.match(\"(?P<PlaneType>[A-Za-z]+.[A-Za-z]*[0-9]+)(?P<FlightNum>[A-Za-z]+\\s[0-9]+)\", st)\n",
    "            if result:\n",
    "                Planetype=result.group('PlaneType')\n",
    "                Flightnumber=result.group('FlightNum')\n",
    "                Flightnumber=Flightnumber.replace('\\xa0','')\n",
    "                #print('Flightnum:',Flightnumber)\n",
    "                #print('Planetype:',Planetype)\n",
    "                BigList[i].append(Flightnumber)\n",
    "                BigList[i].append(Planetype)\n",
    "                #print(\"\")\n",
    "            else:\n",
    "                errormsg=('REGEXerror:',st)\n",
    "                BigList[i].append(errormsg)\n",
    "                BigList[i].append(errormsg)\n",
    "\n",
    "    return BigList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for lists in BigList:\n",
    "    print(len(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super short test set has this many values:8\n",
      "test set has this many values:18\n",
      "full city set has this many values:132\n",
      "full date set has this many values:652\n",
      "full set has this many values:1956\n",
      "come home set has this many values:1956\n"
     ]
    }
   ],
   "source": [
    "##Format URLs, can create these lists:      super_short_test_list//test_urls//full_cities_lessdates_urls//\n",
    "##//full_dates_lesscities_urls//full_url_list//come_home_URLS##\n",
    "\n",
    "cities=['SFO','AUS','ATL','BOI','BOS','CUN','ORD','DEN','DTW','FAI','JFK','SAN']\n",
    "\n",
    "##links look like this for one ways,nonstop, with overhead bags allowed, and frontier airlines excluded##\n",
    "'https://www.google.com/flights?hl=en#flt=SFO.AUS.2019-08-21;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "\n",
    "#This makes all the dates from july 22nd to the end of the year, will update from date time later if i have time\n",
    "dates=['2019-07-22']\n",
    "for days in range(23,32):\n",
    "    date = '2019-07-' + str(days)\n",
    "    dates.append(date)\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-08-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-08-0' + str(days)\n",
    "        dates.append(date)\n",
    "for days in range(1,31):\n",
    "    if days>=10:\n",
    "        date = '2019-09-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-09-0' + str(days)\n",
    "        dates.append(date)\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-10-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-10-0' + str(days)\n",
    "        dates.append(date) \n",
    "\n",
    "for days in range(1,31):\n",
    "    if days>=10:\n",
    "        date = '2019-11-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-11-0' + str(days)\n",
    "        dates.append(date)           \n",
    "\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-12-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-12-0' + str(days)\n",
    "        dates.append(date)         \n",
    "\n",
    "## This makes lists of URLS to use generating data##\n",
    "super_short_test_list=[]\n",
    "super_short_test_list_dates=[]\n",
    "for city in cities[::6]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::43]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        super_short_test_list.append(URL)\n",
    "        super_short_test_list_dates.append(date)\n",
    "        \n",
    "print('super short test set has this many values:'+str(len(super_short_test_list)))\n",
    "\n",
    "test_urls=[]\n",
    "for city in cities[::5]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::29]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        test_urls.append(URL)\n",
    "print('test set has this many values:'+str(len(test_urls)))        \n",
    "        \n",
    "full_cities_lessdates_urls=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::15]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_cities_lessdates_urls.append(URL)\n",
    "print('full city set has this many values:'+str(len(full_cities_lessdates_urls)))   \n",
    "\n",
    "full_dates_lesscities_urls=[]\n",
    "for city in cities[::3]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_dates_lesscities_urls.append(URL)\n",
    "print('full date set has this many values:'+str(len(full_dates_lesscities_urls)))  \n",
    "\n",
    "full_url_list=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_url_list.append(URL)\n",
    "print('full set has this many values:'+str(len(full_url_list)))  \n",
    "\n",
    "come_home_URLS=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt='+city+'.'+'SEA.'\n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        come_home_URLS.append(URL)\n",
    "print('come home set has this many values:'+str(len(come_home_URLS)))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
