{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "driver = webdriver.Chrome('/Users/robjohns/Documents/Metis/Project2/chromedriver')\n",
    "URL=super_short_test_list[0]\n",
    "driver.get(URL)\n",
    "time.sleep(5)\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "driver.quit()\n",
    "print(len(soup.find_all('div', attrs={'class': 'gws-flights-results__itinerary-duration'})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/flights?hl=en#flt=SEA.SFO.2019-07-22;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o\n"
     ]
    }
   ],
   "source": [
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to avoid booting from server ideas . . . .\n",
    "for page in super_short_test_list:\n",
    "    ### scrape a website\n",
    "    ### ...\n",
    "    print(page)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #time.sleep(.5+2*random.random())\n",
    "    \n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.reddit.com'\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = {'User-agent': ua.random}\n",
    "print(user_agent)\n",
    "\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.033"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.03333333333333,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "cost: 236.0\n",
      "Departure Time: 6:00 A\n",
      "Arrival Time: 8:02 A\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 3:45 P\n",
      "Arrival Time: 5:55 P\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 9:25 P\n",
      "Arrival Time: 11:44 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 5:50 A\n",
      "Arrival Time: 8:15 A\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 6:00 A\n",
      "Arrival Time: 8:11 A\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 6:50 A\n",
      "Arrival Time: 9:13 A\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 7:40 A\n",
      "Arrival Time: 10:01 A\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 9:25 A\n",
      "Arrival Time: 11:48 A\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 9:35 A\n",
      "Arrival Time: 12:00 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 10:55 A\n",
      "Arrival Time: 1:20 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 11:15 A\n",
      "Arrival Time: 1:31 P\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 11:50 A\n",
      "Arrival Time: 2:15 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 1:45 P\n",
      "Arrival Time: 3:58 P\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 2:25 P\n",
      "Arrival Time: 4:45 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 3:30 P\n",
      "Arrival Time: 5:50 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 4:05 P\n",
      "Arrival Time: 6:16 P\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 5:15 P\n",
      "Arrival Time: 7:26 P\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 6:35 P\n",
      "Arrival Time: 8:47 P\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 6:59 P\n",
      "Arrival Time: 9:15 P\n",
      "Airline: Delta\n",
      "cost: 236.0\n",
      "Departure Time: 7:25 P\n",
      "Arrival Time: 9:45 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 7:40 P\n",
      "Arrival Time: 9:55 P\n",
      "Airline: United\n",
      "cost: 236.0\n",
      "Departure Time: 8:20 P\n",
      "Arrival Time: 10:40 P\n",
      "Airline: Alaska\n",
      "cost: 236.0\n",
      "Departure Time: 9:34 P\n",
      "Arrival Time: 11:51 P\n",
      "Airline: Delta\n",
      "cost: 238.0\n",
      "Departure Time: 5:12 P\n",
      "Arrival Time: 7:17 P\n",
      "Airline: Delta\n",
      "cost: 259.0\n",
      "Departure Time: 6:00 A\n",
      "Arrival Time: 8:25 A\n",
      "Airline: Alaska\n",
      "cost: 299.0\n",
      "Departure Time: 7:50 A\n",
      "Arrival Time: 10:15 A\n",
      "Airline: Alaska\n",
      "cost: 299.0\n",
      "Departure Time: 9:55 A\n",
      "Arrival Time: 12:14 P\n",
      "Airline: United\n",
      "cost: 299.0\n",
      "Departure Time: 11:33 A\n",
      "Arrival Time: 1:52 P\n",
      "Airline: United\n",
      "cost: 299.0\n",
      "Departure Time: 1:10 P\n",
      "Arrival Time: 3:29 P\n",
      "Airline: United\n",
      "cost: 299.0\n",
      "Departure Time: 5:25 P\n",
      "Arrival Time: 7:45 P\n",
      "Airline: Alaska\n",
      "\n",
      "Flightnum: UA 368\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: DL 2787\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: AS 1330\n",
      "Planetype: Airbus A320\n",
      "\n",
      "no matchy matchy\n",
      "Flightnum: DL 362\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 659\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: DL 2490\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: DL 2429\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: AS 1744\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: AS 304\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: DL 1470\n",
      "Planetype: Airbus A319\n",
      "\n",
      "Flightnum: AS 1748\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: DL 2002\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: AS 1752\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: AS 1754\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: UA 1451\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 587\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 214\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: DL 1190\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: AS 376\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 2070\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: AS 1934\n",
      "Planetype: Airbus A320\n",
      "\n",
      "Flightnum: DL 1657\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: DL 856\n",
      "Planetype: Boeing 717\n",
      "\n",
      "Flightnum: AS 766\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: AS 405\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 698\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: UA 2236\n",
      "Planetype: Boeing 757\n",
      "\n",
      "Flightnum: UA 816\n",
      "Planetype: Boeing 737\n",
      "\n",
      "Flightnum: AS 1756\n",
      "Planetype: Airbus A320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##this will take the soupy html file and pull out data values for all flight results from a search##\n",
    "# looking for [Date,DepartureCity,ArrivalCity,DepartureTime,\n",
    "#               ArrivalTime,FlightDuration,Price,PlaneType,Airline,FlightNumber]\n",
    "import re\n",
    "\n",
    "for li in soup.find_all('div', attrs={'class': 'gws-flights-results__duration flt-subhead1Normal'}):\n",
    "    chonk=li.get_text()\n",
    "    try:\n",
    "        ch=chonk.split('h')\n",
    "        onk=chonk.split(' ')\n",
    "        num2=onk[1]\n",
    "        flight_duration=float(ch[0])+(float(num2[:-1])/60)\n",
    "        flight_duration = round(flight_duration,2)\n",
    "        #print ('flight_duration:',flight_duration)\n",
    "    except:\n",
    "        print('NaN')\n",
    "\n",
    "print('')\n",
    "#for li in soup.find_all('div', attrs={'class': 'gws-flights-results__price'}):\n",
    "    #print(li)\n",
    "\n",
    "print('')\n",
    "\n",
    "for li in soup.find_all('jsl', attrs={'jstcache': \"8836\"}):\n",
    "    #print(li.get_text())\n",
    "    text = li.get_text()\n",
    "    \n",
    "    \n",
    "      #finding price\n",
    "    try:\n",
    "        found = re.search('From (.+?)Trip', text).group(1)\n",
    "        dollar=found.replace(',','')\n",
    "        found=float(dollar[1:-1])\n",
    "    except AttributeError:\n",
    "    # if the sentence structure i didnt expect show up\n",
    "        found = 'NaN' # apply your error handling\n",
    "    print('cost:',found)\n",
    "    \n",
    "    #finding departure and arrival times\n",
    "    try:\n",
    "        found = re.search('Departure time: (.+?)M', text).group(1)\n",
    "        found2 = re.search('Arrival time: (.+?)M', text).group(1)\n",
    "        \n",
    "        #departure=found.replace(',','')\n",
    "        #found=float(dollar[1:-1])\n",
    "    except AttributeError:\n",
    "    # if the sentence structure i didnt expect show up\n",
    "        found = 'NaN' # apply your error handling\n",
    "    print('Departure Time:',found)\n",
    "    print('Arrival Time:',found2)\n",
    "    \n",
    "  \n",
    "    #grab airline\n",
    "    try:\n",
    "        found = re.search('by (.+?).Depa', text).group(1)\n",
    "        \n",
    "        #departure=found.replace(',','')\n",
    "        #found=float(dollar[1:-1])\n",
    "    except AttributeError:\n",
    "    # if the sentence structure i didnt expect show up\n",
    "        found = 'NaN' # apply your error handling\n",
    "    print('Airline:',found)\n",
    "    \n",
    "print('')\n",
    "    #grab PlaneType and flight number\n",
    "for li in soup.find_all('div', attrs={'class': 'gws-flights-results__other-leg-info'}):\n",
    "        #print(li.get_text())\n",
    "        st=li.get_text()\n",
    "        result = re.match(\"(?P<PlaneType>[A-Za-z]+.[A-Za-z]*[0-9]+)(?P<FlightNum>[A-Za-z]+\\s[0-9]+)\", st)\n",
    "        if result:\n",
    "            Planetype=result.group('PlaneType')\n",
    "            Flightnumber=result.group('FlightNum')\n",
    "            print('Flightnum:',Flightnumber)\n",
    "            print('Planetype:',Planetype)\n",
    "            print(\"\")\n",
    "        else:\n",
    "            print('no matchy matchy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has this many values:8\n",
      "test set has this many values:18\n",
      "full city set has this many values:132\n",
      "full date set has this many values:652\n",
      "full set has this many values:1956\n",
      "come home set has this many values:1956\n"
     ]
    }
   ],
   "source": [
    "##Format URLs, can create these lists:      super_short_test_list//test_urls//full_cities_lessdates_urls//\n",
    "##//full_dates_lesscities_urls//full_url_list//come_home_URLS##\n",
    "\n",
    "cities=['SFO','AUS','ATL','BOI','BOS','CUN','ORD','DEN','DTW','FAI','JFK','SAN']\n",
    "\n",
    "##links look like this for one ways,nonstop, with overhead bags allowed, and frontier airlines excluded##\n",
    "'https://www.google.com/flights?hl=en#flt=SFO.AUS.2019-08-21;b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "\n",
    "#This makes all the dates from july 22nd to the end of the year, will update from date time later if i have time\n",
    "dates=['2019-07-22']\n",
    "for days in range(23,32):\n",
    "    date = '2019-07-' + str(days)\n",
    "    dates.append(date)\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-08-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-08-0' + str(days)\n",
    "        dates.append(date)\n",
    "for days in range(1,31):\n",
    "    if days>=10:\n",
    "        date = '2019-09-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-09-0' + str(days)\n",
    "        dates.append(date)\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-10-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-10-0' + str(days)\n",
    "        dates.append(date) \n",
    "\n",
    "for days in range(1,31):\n",
    "    if days>=10:\n",
    "        date = '2019-11-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-11-0' + str(days)\n",
    "        dates.append(date)           \n",
    "\n",
    "for days in range(1,32):\n",
    "    if days>=10:\n",
    "        date = '2019-12-' + str(days)\n",
    "        dates.append(date)\n",
    "    else:\n",
    "        date = '2019-12-0' + str(days)\n",
    "        dates.append(date)         \n",
    "\n",
    "## This makes lists of URLS to use generating data##\n",
    "super_short_test_list=[]\n",
    "for city in cities[::6]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::43]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        super_short_test_list.append(URL)\n",
    "print('super short test set has this many values:'+str(len(super_short_test_list)))\n",
    "\n",
    "test_urls=[]\n",
    "for city in cities[::5]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::29]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        test_urls.append(URL)\n",
    "print('test set has this many values:'+str(len(test_urls)))        \n",
    "        \n",
    "full_cities_lessdates_urls=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates[::15]:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_cities_lessdates_urls.append(URL)\n",
    "print('full city set has this many values:'+str(len(full_cities_lessdates_urls)))   \n",
    "\n",
    "full_dates_lesscities_urls=[]\n",
    "for city in cities[::3]:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_dates_lesscities_urls.append(URL)\n",
    "print('full date set has this many values:'+str(len(full_dates_lesscities_urls)))  \n",
    "\n",
    "full_url_list=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt=SEA.'+city+'.'\n",
    "    \n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        full_url_list.append(URL)\n",
    "print('full set has this many values:'+str(len(full_url_list)))  \n",
    "\n",
    "come_home_URLS=[]\n",
    "for city in cities:\n",
    "    URLc='https://www.google.com/flights?hl=en#flt='+city+'.'+'SEA.'\n",
    "    for date in dates:\n",
    "        URL=URLc+date+';b:1;c:USD;e:1;s:0;a:-F9;sd:1;t:f;tt:o'\n",
    "        come_home_URLS.append(URL)\n",
    "print('come home set has this many values:'+str(len(come_home_URLS)))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
